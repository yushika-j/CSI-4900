{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WMMLzlEFg2_W"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "urlTrain = \"https://raw.githubusercontent.com/awsm-research/VulRepair/refs/heads/main/data/fine_tune_data/train.csv\"\n",
        "urlTest = \"https://raw.githubusercontent.com/awsm-research/VulRepair/refs/heads/main/data/fine_tune_data/test.csv\"\n",
        "urlVal = \"https://raw.githubusercontent.com/awsm-research/VulRepair/refs/heads/main/data/fine_tune_data/val.csv\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "train_df = pd.read_csv(urlTrain)\n",
        "test_df = pd.read_csv(urlTest)\n",
        "val_df = pd.read_csv(urlVal)"
      ],
      "metadata": {
        "id": "BMEhSwqEhDvK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_inter_duplicates(source_df, *target_dfs):\n",
        "    \"\"\"\n",
        "    Removes rows from source_df that are present in any of the target_dfs.\n",
        "    \"\"\"\n",
        "    if not target_dfs:\n",
        "        return source_df\n",
        "    # Combine target DataFrames and drop duplicates within them\n",
        "    combined_target = pd.concat(target_dfs).drop_duplicates()\n",
        "    # Merge to find overlapping rows\n",
        "    merged = source_df.merge(combined_target, on=list(source_df.columns),\n",
        "                        how='left', indicator=True)\n",
        "    # Keep only rows unique to source_df\n",
        "    cleaned_df = merged[merged['_merge'] == 'left_only'].drop(columns='_merge')\n",
        "    return cleaned_df"
      ],
      "metadata": {
        "id": "BidPtnX_hR8w"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store original sizes\n",
        "original_sizes = {\n",
        "    'train': len(train_df),\n",
        "    'val': len(val_df),\n",
        "    'test': len(test_df),\n",
        "}\n",
        "\n",
        "# Process train dataset\n",
        "train_df = train_df.drop_duplicates()  # Intra duplicates\n",
        "train_df = remove_inter_duplicates(train_df, val_df, test_df)  # Inter duplicates\n",
        "\n",
        "# Process val dataset\n",
        "val_df = val_df.drop_duplicates()  # Intra duplicates\n",
        "val_df = remove_inter_duplicates(val_df, test_df)  # Inter duplicates\n",
        "\n",
        "# Process test dataset\n",
        "test_df = test_df.drop_duplicates()  # Intra duplicates"
      ],
      "metadata": {
        "id": "xdpNfcdyhaI3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate new sizes\n",
        "new_sizes = {\n",
        "    'train': len(train_df),\n",
        "    'val': len(val_df),\n",
        "    'test': len(test_df),\n",
        "}\n",
        "\n",
        "# Calculate total size\n",
        "total_cleaned = sum(new_sizes.values())\n",
        "\n",
        "# Print original and new proportions\n",
        "print(\"Original sizes:\")\n",
        "for dataset, size in original_sizes.items():\n",
        "    print(f\"{dataset}: {size} rows ({size / sum(original_sizes.values()):.2%})\")\n",
        "\n",
        "print(\"\\nNew sizes after deduplication:\")\n",
        "for dataset, size in new_sizes.items():\n",
        "    print(f\"{dataset}: {size} rows ({size / total_cleaned:.2%})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6mz41tyhdKB",
        "outputId": "5a7449a6-c8aa-4a42-fd37-f3adc51a114c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original sizes:\n",
            "train: 5937 rows (70.00%)\n",
            "val: 839 rows (9.89%)\n",
            "test: 1706 rows (20.11%)\n",
            "\n",
            "New sizes after deduplication:\n",
            "train: 3777 rows (61.88%)\n",
            "val: 713 rows (11.68%)\n",
            "test: 1614 rows (26.44%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zwIZRgA8hgB8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}